{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78da1b7f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There was a problem when trying to write in your cache folder (/work/.cache/huggingface/hub). You should set the environment variable TRANSFORMERS_CACHE to a writable directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizerFast(name_or_path='./pretrained_models/chinese-macbert-base', vocab_size=21128, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 8913, 8510, 8343, 11634, 11137, 8670, 8174, 9519, 10858, 8315, 12816, 8118, 102], [101, 11485, 8383, 9556, 8275, 8541, 8165, 117, 10110, 11441, 9132, 8168, 11005, 9726, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('./pretrained_models/chinese-macbert-base')\n",
    "\n",
    "print(tokenizer)\n",
    "\n",
    "tokenizer.batch_encode_plus([\n",
    "    'hide new secretions from the parental units',\n",
    "    'contains no wit , only labored gags'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4362e608",
   "metadata": {},
   "source": [
    "# 定义数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0792d11e",
   "metadata": {},
   "source": [
    "## numpy array 转 pytorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b148e5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2176, 725, 726, ('上海协调机制出台首份政策文件 持续加大复工复产金融支持', 1))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, split):\n",
    "        data = np.load('./data/5.news_data/news_matrix_fine_tuning.npy', allow_pickle=True) \n",
    "\n",
    "        data_0 = data[data[:, 1] == 0] \n",
    "        data_1 = data[data[:, 1] == 1] \n",
    "\n",
    "\n",
    "        data = np.concatenate([data_0, data_1])\n",
    "\n",
    "\n",
    "        # train_len = int(len(data) * 0.8) \n",
    "        train_len = int(len(data) * 0.6)\n",
    "        val_len =  int(len(data) * 0.2)\n",
    "        # test_len = len(data) - train_len \n",
    "        test_len = len(data) - train_len - val_len\n",
    "        train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(dataset = data.tolist(), lengths = [train_len, val_len, test_len], generator = torch.Generator().manual_seed(1))\n",
    "        \n",
    "        if split == 'train':\n",
    "            data = train_dataset\n",
    "        elif split == 'valid':\n",
    "            data = valid_dataset\n",
    "        elif split == 'test':\n",
    "            data = test_dataset\n",
    "\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        text = self.data[i][0]\n",
    "        label = self.data[i][1]\n",
    "\n",
    "        return text, label\n",
    "\n",
    "len(Dataset('train')), len(Dataset('valid')), len(Dataset('test')), Dataset('train')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa89204",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312fb8d3",
   "metadata": {},
   "source": [
    "## 自定义 collate_fn 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05cffcc8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def collate_fn(batch):  \n",
    "    sents = [i[0] for i in batch]\n",
    "    labels = [i[1] for i in batch]\n",
    "\n",
    "\n",
    "    batch = tokenizer.batch_encode_plus( \n",
    "        batch_text_or_text_pairs=sents,\n",
    "        padding='longest', \n",
    "        add_special_tokens = True, \n",
    "        return_tensors='pt')\n",
    "\n",
    "    input_ids = batch['input_ids']\n",
    "    attention_mask = batch['attention_mask']\n",
    "    token_type_ids = batch['token_type_ids']\n",
    "    labels = torch.LongTensor(labels)\n",
    "\n",
    "    return input_ids, attention_mask, token_type_ids, labels "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3813e6",
   "metadata": {},
   "source": [
    "## train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1afc34a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 40]),\n",
       " torch.Size([16, 40]),\n",
       " torch.Size([16, 40]),\n",
       " tensor([0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=Dataset('train'),\n",
    "    batch_size=16,  \n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=True,  \n",
    "    drop_last=True) \n",
    "\n",
    "for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(train_dataloader): \n",
    "    break \n",
    "\n",
    "print(len(train_dataloader)) \n",
    "input_ids.shape, attention_mask.shape, token_type_ids.shape, labels "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4f150c",
   "metadata": {},
   "source": [
    "## valid_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bad11b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 44]),\n",
       " torch.Size([16, 44]),\n",
       " torch.Size([16, 44]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=Dataset('valid'),\n",
    "    batch_size=16, \n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(valid_dataloader): \n",
    "    break \n",
    "\n",
    "print(len(valid_dataloader)) \n",
    "input_ids.shape, attention_mask.shape, token_type_ids.shape, labels "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b11079b",
   "metadata": {},
   "source": [
    "## test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ca2b2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 41]),\n",
       " torch.Size([16, 41]),\n",
       " torch.Size([16, 41]),\n",
       " tensor([0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=Dataset('test'),\n",
    "    batch_size=16, \n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(test_dataloader): \n",
    "    break \n",
    "\n",
    "print(len(test_dataloader)) \n",
    "input_ids.shape, attention_mask.shape, token_type_ids.shape, labels "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a309a42c",
   "metadata": {},
   "source": [
    "# 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "274662dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./pretrained_models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10285.9778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.7349, grad_fn=<NllLossBackward0>), torch.Size([16, 2]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "        self.pretrained = BertModel.from_pretrained('./model/pre_trained_bert/chinese-macbert-base') \n",
    "\n",
    "        self.fc = torch.nn.Sequential(torch.nn.Linear(768, 768),\n",
    "                                      torch.nn.ReLU(), \n",
    "                                      torch.nn.Dropout(p=0.2),\n",
    "                                      torch.nn.Linear(768, 2))\n",
    "        \n",
    "        self.criterion = torch.nn.CrossEntropyLoss() \n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, labels=None):\n",
    "        logits = self.pretrained(input_ids=input_ids, \n",
    "                                 attention_mask=attention_mask,\n",
    "                                 token_type_ids=token_type_ids)\n",
    "        logits = logits.last_hidden_state[:, 0] \n",
    "        logits = self.fc(logits)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.criterion(logits, labels)\n",
    "\n",
    "        return {'loss': loss, 'logits': logits} \n",
    "\n",
    "model = Model() \n",
    "\n",
    "print(sum(i.numel() for i in model.parameters()) / 10000)\n",
    "\n",
    "out = model(input_ids, attention_mask, token_type_ids, labels)\n",
    "\n",
    "out['loss'], out['logits'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c682ab70",
   "metadata": {},
   "source": [
    "# 测试函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15e07dac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def test(model,test_dataloader):\n",
    "    print(\"Running Test...\")\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "    print('device=', device)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loop = tqdm(enumerate(test_dataloader), total =len(test_dataloader), desc='Test progress bar', file=sys.stdout)\n",
    "    for i, (input_ids, attention_mask, token_type_ids, labels) in loop:\n",
    "        \n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        token_type_ids = token_type_ids.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        with torch.no_grad(): \n",
    "            out = model(input_ids, attention_mask, token_type_ids, None)\n",
    "        \n",
    "        correct += (out['logits'].argmax(dim=1) == labels).sum().item()\n",
    "        total += len(labels)\n",
    "    \n",
    "    print(\"Test Acc: {}\".format(correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe96a77e",
   "metadata": {},
   "source": [
    "# 训练函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76ae4cb",
   "metadata": {},
   "source": [
    "## 加验证集训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d931fca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from transformers.optimization import get_scheduler\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "from tqdm import tqdm \n",
    "\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "def train(model, train_dataloader, valid_dataloader, num_epoch):\n",
    "    print(\"Running Train...\")\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "    print('device=', device)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    num_epoch = num_epoch\n",
    "    total_steps = len(train_dataloader) * num_epoch\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5) \n",
    "    scheduler = get_scheduler(name='linear',\n",
    "                              num_warmup_steps=0, \n",
    "                              num_training_steps=total_steps,  \n",
    "                              optimizer=optimizer)\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        \n",
    "        print(\"——————Epoch {:} / {:} ——————\".format(epoch + 1,num_epoch))\n",
    "\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        model.train() \n",
    "        \n",
    "        total_train_acc = 0\n",
    "        total_train_loss = 0\n",
    "\n",
    "        loop = tqdm(enumerate(train_dataloader), total =len(train_dataloader), desc='Train progress bar', file=sys.stdout) \n",
    "        for i, (input_ids, attention_mask, token_type_ids, labels) in loop:\n",
    "           \n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            token_type_ids = token_type_ids.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad() \n",
    "            model.zero_grad() \n",
    "\n",
    "            out = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids,\n",
    "                labels=labels,\n",
    "            )\n",
    "\n",
    "            loss = out['loss']\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    " \n",
    "            optimizer.step() \n",
    "            scheduler.step() \n",
    "            \n",
    "            out = out['logits'].argmax(dim=1)\n",
    "            accuracy = (labels == out).sum().item() / len(labels) \n",
    "            total_train_acc += accuracy\n",
    "            total_train_loss += loss\n",
    "            \n",
    "            if i % 50 == 0:    \n",
    "                tqdm.write(\"Batch: {}, Train Acc: {}, Train Loss: {}, Lr: {}\".format(i, accuracy, loss.item(), optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "        \n",
    "        training_time = format_time(time.time() - start)\n",
    "        print(\"Epoch: {}, Train Acc: {}, Train Loss: {}, Lr: {}, Time: {}\".format(epoch, total_train_acc/len(train_dataloader), total_train_loss/len(train_dataloader), optimizer.state_dict()['param_groups'][0]['lr'], training_time))               \n",
    "   \n",
    "        print(\"Running Validation...\")\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        total_valid_acc = 0\n",
    "        total_valid_loss = 0\n",
    "\n",
    "        loop = tqdm(enumerate(valid_dataloader), total =len(valid_dataloader), desc='Valid progress bar', file=sys.stdout)\n",
    "        for i, (input_ids, attention_mask, token_type_ids, labels) in loop:\n",
    "\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            token_type_ids = token_type_ids.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            with torch.no_grad(): \n",
    "                out = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    token_type_ids=token_type_ids,\n",
    "                    labels=labels,\n",
    "                )\n",
    "                loss = out['loss']\n",
    "                out = out['logits'].argmax(dim=1)\n",
    "                accuracy = (labels == out).sum().item() / len(labels) \n",
    "            \n",
    "            total_valid_acc += accuracy\n",
    "            total_valid_loss += loss\n",
    "        \n",
    "        print(\"Valid Acc: {}, Valid Loss: {}\".format(total_valid_acc/len(valid_dataloader),total_valid_loss/len(valid_dataloader))) \n",
    "    \n",
    "    torch.save(model, './fine-tuning-add-epoch-gpu-valid-30epoch.model') # modify path to './fine-tuned-bert.model'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf98bd85",
   "metadata": {},
   "source": [
    "# 加载模型并测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5e7d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,test_dataloader):\n",
    "    print(\"Running Test...\")\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "    print('device=', device)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    loop = tqdm(enumerate(test_dataloader), total =len(test_dataloader), desc='Test progress bar', file=sys.stdout)\n",
    "    \n",
    "    labels_list = []\n",
    "    outs_list = []\n",
    "    \n",
    "    for i, (input_ids, attention_mask, token_type_ids, labels) in loop:\n",
    "        \n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        token_type_ids = token_type_ids.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            out = model(input_ids, attention_mask, token_type_ids, None)\n",
    "        \n",
    "        labels_list.append(labels.tolist())\n",
    "        outs_list.append((out['logits'].argmax(dim=1)).tolist())\n",
    "        \n",
    "        correct += (out['logits'].argmax(dim=1) == labels).sum().item()\n",
    "        total += len(labels)\n",
    "        \n",
    "    print(\"Test Acc: {}\".format(correct / total))\n",
    "    return labels_list, outs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1677de8",
   "metadata": {},
   "source": [
    "# 定义Main函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ee4bce9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./pretrained_models/chinese-macbert-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/media/cfs/luzhiqiang23/.pylib/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Train...\n",
      "device= cuda\n",
      "——————Epoch 1 / 30 ——————\n",
      "Batch: 0, Train Acc: 0.375, Train Loss: 0.7514275908470154, Lr: 1.9995098039215686e-05\n",
      "Batch: 50, Train Acc: 1.0, Train Loss: 0.22080090641975403, Lr: 1.9750000000000002e-05\n",
      "Batch: 100, Train Acc: 1.0, Train Loss: 0.07771937549114227, Lr: 1.9504901960784315e-05\n",
      "Train progress bar: 100%|██████████| 136/136 [01:09<00:00,  1.97it/s]\n",
      "Epoch: 0, Train Acc: 0.8405330882352942, Train Loss: 0.361802339553833, Lr: 1.9333333333333333e-05, Time: 0:01:09\n",
      "Running Validation...\n",
      "Valid progress bar: 100%|██████████| 45/45 [00:05<00:00,  7.70it/s]\n",
      "Valid Acc: 0.925, Valid Loss: 0.22786585986614227\n",
      "——————Epoch 2 / 30 ——————\n",
      "Batch: 0, Train Acc: 1.0, Train Loss: 0.11732280254364014, Lr: 1.932843137254902e-05\n",
      "Batch: 50, Train Acc: 1.0, Train Loss: 0.03351026028394699, Lr: 1.9083333333333338e-05\n",
      "Batch: 100, Train Acc: 0.9375, Train Loss: 0.23448705673217773, Lr: 1.8838235294117647e-05\n",
      "Train progress bar: 100%|██████████| 136/136 [01:05<00:00,  2.09it/s]\n",
      "Epoch: 1, Train Acc: 0.9342830882352942, Train Loss: 0.1993894875049591, Lr: 1.866666666666667e-05, Time: 0:01:05\n",
      "Running Validation...\n",
      "Valid progress bar: 100%|██████████| 45/45 [00:05<00:00,  8.38it/s]\n",
      "Valid Acc: 0.9125, Valid Loss: 0.2571772634983063\n",
      "——————Epoch 3 / 30 ——————\n",
      "Batch: 0, Train Acc: 1.0, Train Loss: 0.06341372430324554, Lr: 1.8661764705882353e-05\n",
      "Batch: 50, Train Acc: 1.0, Train Loss: 0.005658922716975212, Lr: 1.8416666666666666e-05\n",
      "Batch: 100, Train Acc: 1.0, Train Loss: 0.025885505601763725, Lr: 1.8171568627450982e-05\n",
      "Train progress bar: 100%|██████████| 136/136 [01:12<00:00,  1.87it/s]\n",
      "Epoch: 2, Train Acc: 0.9719669117647058, Train Loss: 0.10583297163248062, Lr: 1.8e-05, Time: 0:01:13\n",
      "Running Validation...\n",
      "Valid progress bar: 100%|██████████| 45/45 [00:04<00:00,  9.01it/s]\n",
      "Valid Acc: 0.9055555555555556, Valid Loss: 0.3946813941001892\n",
      "——————Epoch 4 / 30 ——————\n",
      "Batch: 0, Train Acc: 1.0, Train Loss: 0.0067702108062803745, Lr: 1.799509803921569e-05\n",
      "Batch: 50, Train Acc: 1.0, Train Loss: 0.0037715572398155928, Lr: 1.775e-05\n",
      "Batch: 100, Train Acc: 1.0, Train Loss: 0.004249763675034046, Lr: 1.7504901960784314e-05\n",
      "Train progress bar: 100%|██████████| 136/136 [01:07<00:00,  2.02it/s]\n",
      "Epoch: 3, Train Acc: 0.9761029411764706, Train Loss: 0.08645371347665787, Lr: 1.7333333333333336e-05, Time: 0:01:08\n",
      "Running Validation...\n",
      "Valid progress bar: 100%|██████████| 45/45 [00:06<00:00,  7.21it/s]\n",
      "Valid Acc: 0.9194444444444444, Valid Loss: 0.40539929270744324\n",
      "——————Epoch 5 / 30 ——————\n",
      "Batch: 0, Train Acc: 0.9375, Train Loss: 0.1894359439611435, Lr: 1.732843137254902e-05\n",
      "Batch: 50, Train Acc: 1.0, Train Loss: 0.008268116042017937, Lr: 1.7083333333333333e-05\n",
      "Batch: 100, Train Acc: 1.0, Train Loss: 0.0037422901950776577, Lr: 1.683823529411765e-05\n",
      "Train progress bar: 100%|██████████| 136/136 [01:11<00:00,  1.92it/s]\n",
      "Epoch: 4, Train Acc: 0.9875919117647058, Train Loss: 0.05110397934913635, Lr: 1.6666666666666667e-05, Time: 0:01:11\n",
      "Running Validation...\n",
      "Valid progress bar: 100%|██████████| 45/45 [00:05<00:00,  7.84it/s]\n",
      "Valid Acc: 0.9208333333333333, Valid Loss: 0.43511998653411865\n",
      "——————Epoch 6 / 30 ——————\n",
      "Batch: 0, Train Acc: 1.0, Train Loss: 0.028241164982318878, Lr: 1.6661764705882356e-05\n",
      "Batch: 50, Train Acc: 1.0, Train Loss: 0.0009424436721019447, Lr: 1.6416666666666668e-05\n",
      "Batch: 100, Train Acc: 1.0, Train Loss: 0.0006726162973791361, Lr: 1.617156862745098e-05\n",
      "Train progress bar: 100%|██████████| 136/136 [01:11<00:00,  1.91it/s]\n",
      "Epoch: 5, Train Acc: 0.9954044117647058, Train Loss: 0.016820913180708885, Lr: 1.6000000000000003e-05, Time: 0:01:11\n",
      "Running Validation...\n",
      "Valid progress bar: 100%|██████████| 45/45 [00:06<00:00,  6.86it/s]\n",
      "Valid Acc: 0.8847222222222222, Valid Loss: 0.6368099451065063\n",
      "——————Epoch 7 / 30 ——————\n",
      "Batch: 0, Train Acc: 1.0, Train Loss: 0.0033708466216921806, Lr: 1.5995098039215687e-05\n",
      "Batch: 50, Train Acc: 1.0, Train Loss: 0.0005045390571467578, Lr: 1.575e-05\n",
      "Batch: 100, Train Acc: 1.0, Train Loss: 0.0003385754826012999, Lr: 1.5504901960784316e-05\n",
      "Train progress bar: 100%|██████████| 136/136 [01:17<00:00,  1.76it/s]\n",
      "Epoch: 6, Train Acc: 0.9967830882352942, Train Loss: 0.010477855801582336, Lr: 1.5333333333333334e-05, Time: 0:01:17\n",
      "Running Validation...\n",
      "Valid progress bar: 100%|██████████| 45/45 [00:06<00:00,  7.41it/s]\n",
      "Valid Acc: 0.9138888888888889, Valid Loss: 0.5513232946395874\n",
      "——————Epoch 8 / 30 ——————\n",
      "Batch: 0, Train Acc: 1.0, Train Loss: 0.0004534120380412787, Lr: 1.5328431372549023e-05\n",
      "Batch: 50, Train Acc: 1.0, Train Loss: 0.0003402055590413511, Lr: 1.5083333333333333e-05\n",
      "Batch: 100, Train Acc: 1.0, Train Loss: 0.00031672557815909386, Lr: 1.483823529411765e-05\n",
      "Train progress bar: 100%|██████████| 136/136 [01:10<00:00,  1.93it/s]\n",
      "Epoch: 7, Train Acc: 1.0, Train Loss: 0.0008568486664444208, Lr: 1.4666666666666666e-05, Time: 0:01:11\n",
      "Running Validation...\n",
      "Valid progress bar: 100%|██████████| 45/45 [00:05<00:00,  7.80it/s]\n",
      "Valid Acc: 0.9152777777777777, Valid Loss: 0.5966984629631042\n",
      "——————Epoch 9 / 30 ——————\n",
      "Batch: 0, Train Acc: 1.0, Train Loss: 0.00029495565104298294, Lr: 1.4661764705882353e-05\n",
      "Batch: 50, Train Acc: 1.0, Train Loss: 0.0002281401539221406, Lr: 1.4416666666666667e-05\n",
      "Batch: 100, Train Acc: 1.0, Train Loss: 0.0003005070611834526, Lr: 1.4171568627450983e-05\n",
      "Train progress bar: 100%|██████████| 136/136 [01:10<00:00,  1.92it/s]\n",
      "Epoch: 8, Train Acc: 1.0, Train Loss: 0.0002969065972138196, Lr: 1.4e-05, Time: 0:01:11\n",
      "Running Validation...\n",
      "Valid progress bar: 100%|██████████| 45/45 [00:05<00:00,  8.00it/s]\n",
      "Valid Acc: 0.9138888888888889, Valid Loss: 0.6076862215995789\n",
      "——————Epoch 10 / 30 ——————\n",
      "Batch: 0, Train Acc: 1.0, Train Loss: 0.00013796622806694359, Lr: 1.3995098039215686e-05\n",
      "Batch: 50, Train Acc: 1.0, Train Loss: 0.00010700566781451926, Lr: 1.375e-05\n",
      "Batch: 100, Train Acc: 1.0, Train Loss: 9.601700003258884e-05, Lr: 1.3504901960784316e-05\n",
      "Train progress bar: 100%|██████████| 136/136 [01:13<00:00,  1.84it/s]\n",
      "Epoch: 9, Train Acc: 0.9990808823529411, Train Loss: 0.003228516783565283, Lr: 1.3333333333333333e-05, Time: 0:01:14\n",
      "Running Validation...\n",
      "Valid progress bar: 100%|██████████| 45/45 [00:06<00:00,  6.53it/s]\n",
      "Valid Acc: 0.9180555555555555, Valid Loss: 0.6342265605926514\n",
      "——————Epoch 11 / 30 ——————\n",
      "Batch: 0, Train Acc: 1.0, Train Loss: 0.00013385283818934113, Lr: 1.332843137254902e-05\n",
      "Batch: 50, Train Acc: 1.0, Train Loss: 0.00010011444101110101, Lr: 1.3083333333333334e-05\n",
      "Batch: 100, Train Acc: 1.0, Train Loss: 0.00027219593175686896, Lr: 1.2838235294117648e-05\n",
      "Train progress bar: 100%|██████████| 136/136 [01:12<00:00,  1.88it/s]\n",
      "Epoch: 10, Train Acc: 0.9986213235294118, Train Loss: 0.005224559921771288, Lr: 1.2666666666666667e-05, Time: 0:01:12\n",
      "Running Validation...\n",
      "Valid progress bar: 100%|██████████| 45/45 [00:05<00:00,  7.75it/s]\n",
      "Valid Acc: 0.9222222222222223, Valid Loss: 0.6310093998908997\n",
      "——————Epoch 12 / 30 ——————\n",
      "Batch: 0, Train Acc: 1.0, Train Loss: 0.00011054123751819134, Lr: 1.2661764705882353e-05\n",
      "Batch: 50, Train Acc: 1.0, Train Loss: 0.0001431492273695767, Lr: 1.2416666666666667e-05\n",
      "Batch: 100, Train Acc: 1.0, Train Loss: 9.051180677488446e-05, Lr: 1.217156862745098e-05\n",
      "Train progress bar: 100%|██████████| 136/136 [01:12<00:00,  1.88it/s]\n",
      "Epoch: 11, Train Acc: 0.9990808823529411, Train Loss: 0.0048582954332232475, Lr: 1.2e-05, Time: 0:01:13\n",
      "Running Validation...\n",
      "Valid progress bar: 100%|██████████| 45/45 [00:05<00:00,  7.79it/s]\n",
      "Valid Acc: 0.9194444444444444, Valid Loss: 0.6527622938156128\n",
      "——————Epoch 13 / 30 ——————\n",
      "Batch: 0, Train Acc: 1.0, Train Loss: 0.0006624129600822926, Lr: 1.1995098039215687e-05\n",
      "Batch: 50, Train Acc: 1.0, Train Loss: 8.196734415832907e-05, Lr: 1.1750000000000001e-05\n",
      "Batch: 100, Train Acc: 1.0, Train Loss: 0.0002199833543272689, Lr: 1.1504901960784314e-05\n",
      "Train progress bar: 100%|██████████| 136/136 [01:11<00:00,  1.90it/s]\n",
      "Epoch: 12, Train Acc: 1.0, Train Loss: 9.891263471217826e-05, Lr: 1.1333333333333334e-05, Time: 0:01:12\n",
      "Running Validation...\n",
      "Valid progress bar: 100%|██████████| 45/45 [00:06<00:00,  7.36it/s]\n",
      "Valid Acc: 0.9180555555555555, Valid Loss: 0.6892418265342712\n",
      "——————Epoch 14 / 30 ——————\n",
      "Batch: 0, Train Acc: 1.0, Train Loss: 7.538143108831719e-05, Lr: 1.132843137254902e-05\n",
      "Batch: 50, Train Acc: 1.0, Train Loss: 7.604446000186726e-05, Lr: 1.1083333333333335e-05\n",
      "Batch: 100, Train Acc: 1.0, Train Loss: 5.581056757364422e-05, Lr: 1.0838235294117647e-05\n",
      "Train progress bar: 100%|██████████| 136/136 [01:17<00:00,  1.75it/s]\n",
      "Epoch: 13, Train Acc: 0.9995404411764706, Train Loss: 0.0022422149777412415, Lr: 1.0666666666666667e-05, Time: 0:01:18\n",
      "Running Validation...\n",
      "Valid progress bar: 100%|██████████| 45/45 [00:06<00:00,  7.41it/s]\n",
      "Valid Acc: 0.9166666666666666, Valid Loss: 0.709637463092804\n",
      "——————Epoch 15 / 30 ——————\n",
      "Batch: 0, Train Acc: 1.0, Train Loss: 7.978425855981186e-05, Lr: 1.0661764705882354e-05\n",
      "Batch: 50, Train Acc: 1.0, Train Loss: 5.3329426009440795e-05, Lr: 1.0416666666666668e-05\n",
      "Batch: 100, Train Acc: 1.0, Train Loss: 5.100523412693292e-05, Lr: 1.017156862745098e-05\n",
      "Train progress bar: 100%|██████████| 136/136 [01:11<00:00,  1.90it/s]\n",
      "Epoch: 14, Train Acc: 1.0, Train Loss: 8.500615513185039e-05, Lr: 1e-05, Time: 0:01:12\n",
      "Running Validation...\n",
      "Valid progress bar: 100%|██████████| 45/45 [00:06<00:00,  7.46it/s]\n",
      "Valid Acc: 0.9222222222222223, Valid Loss: 0.6864293813705444\n",
      "——————Epoch 16 / 30 ——————\n",
      "Batch: 0, Train Acc: 1.0, Train Loss: 5.4834370530443266e-05, Lr: 9.995098039215687e-06\n",
      "Batch: 50, Train Acc: 1.0, Train Loss: 4.938086203765124e-05, Lr: 9.75e-06\n",
      "Batch: 100, Train Acc: 1.0, Train Loss: 8.303448703372851e-05, Lr: 9.504901960784314e-06\n",
      "Train progress bar: 100%|██████████| 136/136 [01:11<00:00,  1.91it/s]\n",
      "Epoch: 15, Train Acc: 1.0, Train Loss: 6.700070662191138e-05, Lr: 9.333333333333334e-06, Time: 0:01:11\n",
      "Running Validation...\n",
      "Valid progress bar: 100%|██████████| 45/45 [00:06<00:00,  7.36it/s]\n",
      "Valid Acc: 0.9055555555555556, Valid Loss: 0.8304327130317688\n",
      "——————Epoch 17 / 30 ——————\n",
      "Batch: 0, Train Acc: 1.0, Train Loss: 5.6019089242909104e-05, Lr: 9.32843137254902e-06\n",
      "Batch: 50, Train Acc: 1.0, Train Loss: 5.0155726057710126e-05, Lr: 9.083333333333333e-06\n",
      "Batch: 100, Train Acc: 1.0, Train Loss: 4.074616663274355e-05, Lr: 8.838235294117648e-06\n",
      "Train progress bar: 100%|██████████| 136/136 [01:15<00:00,  1.81it/s]\n",
      "Epoch: 16, Train Acc: 1.0, Train Loss: 5.9789490478578955e-05, Lr: 8.666666666666668e-06, Time: 0:01:15\n",
      "Running Validation...\n",
      "Valid progress bar: 100%|██████████| 45/45 [00:07<00:00,  6.30it/s]\n",
      "Valid Acc: 0.9138888888888889, Valid Loss: 0.7342316508293152\n",
      "——————Epoch 18 / 30 ——————\n",
      "Batch: 0, Train Acc: 1.0, Train Loss: 5.608596984529868e-05, Lr: 8.661764705882354e-06\n",
      "Batch: 50, Train Acc: 1.0, Train Loss: 6.863893213449046e-05, Lr: 8.416666666666667e-06\n",
      "Batch: 100, Train Acc: 1.0, Train Loss: 4.329415241954848e-05, Lr: 8.171568627450981e-06\n",
      "Train progress bar: 100%|██████████| 136/136 [01:14<00:00,  1.82it/s]\n",
      "Epoch: 17, Train Acc: 0.9995404411764706, Train Loss: 0.0011081520933657885, Lr: 8.000000000000001e-06, Time: 0:01:15\n",
      "Running Validation...\n",
      "Valid progress bar: 100%|██████████| 45/45 [00:05<00:00,  7.66it/s]\n",
      "Valid Acc: 0.9180555555555555, Valid Loss: 0.7244633436203003\n",
      "——————Epoch 19 / 30 ——————\n",
      "Batch: 0, Train Acc: 1.0, Train Loss: 4.359963349997997e-05, Lr: 7.995098039215688e-06\n",
      "Batch: 50, Train Acc: 1.0, Train Loss: 4.9254438636126e-05, Lr: 7.75e-06\n",
      "Batch: 100, Train Acc: 1.0, Train Loss: 4.9336023948853835e-05, Lr: 7.504901960784315e-06\n",
      "Train progress bar: 100%|██████████| 136/136 [01:12<00:00,  1.88it/s]\n",
      "Epoch: 18, Train Acc: 0.9995404411764706, Train Loss: 0.0038667465560138226, Lr: 7.333333333333333e-06, Time: 0:01:13\n",
      "Running Validation...\n",
      "Valid progress bar: 100%|██████████| 45/45 [00:06<00:00,  7.30it/s]\n",
      "Valid Acc: 0.9138888888888889, Valid Loss: 0.7502201795578003\n",
      "——————Epoch 20 / 30 ——————\n",
      "Batch: 0, Train Acc: 1.0, Train Loss: 3.672308594104834e-05, Lr: 7.3284313725490195e-06\n",
      "Batch: 50, Train Acc: 1.0, Train Loss: 4.7816029109526426e-05, Lr: 7.083333333333335e-06\n",
      "Batch: 100, Train Acc: 1.0, Train Loss: 4.287670162739232e-05, Lr: 6.838235294117648e-06\n",
      "Train progress bar: 100%|██████████| 136/136 [01:12<00:00,  1.87it/s]\n",
      "Epoch: 19, Train Acc: 1.0, Train Loss: 4.14379064750392e-05, Lr: 6.666666666666667e-06, Time: 0:01:13\n",
      "Running Validation...\n",
      "Valid progress bar: 100%|██████████| 45/45 [00:06<00:00,  7.46it/s]\n",
      "Valid Acc: 0.9194444444444444, Valid Loss: 0.7446193695068359\n",
      "——————Epoch 21 / 30 ——————\n",
      "Batch: 0, Train Acc: 1.0, Train Loss: 3.547869710018858e-05, Lr: 6.661764705882353e-06\n",
      "Batch: 50, Train Acc: 1.0, Train Loss: 3.896546331816353e-05, Lr: 6.416666666666667e-06\n",
      "Batch: 100, Train Acc: 1.0, Train Loss: 4.4389336835592985e-05, Lr: 6.171568627450981e-06\n",
      "Train progress bar: 100%|██████████| 136/136 [01:18<00:00,  1.72it/s]\n",
      "Epoch: 20, Train Acc: 1.0, Train Loss: 3.7897250876994804e-05, Lr: 6e-06, Time: 0:01:19\n",
      "Running Validation...\n",
      "Valid progress bar: 100%|██████████| 45/45 [00:06<00:00,  7.40it/s]\n",
      "Valid Acc: 0.9194444444444444, Valid Loss: 0.7642775177955627\n",
      "——————Epoch 22 / 30 ——————\n",
      "Batch: 0, Train Acc: 1.0, Train Loss: 3.500189268379472e-05, Lr: 5.9950980392156865e-06\n",
      "Batch: 50, Train Acc: 1.0, Train Loss: 3.171655043843202e-05, Lr: 5.75e-06\n",
      "Batch: 100, Train Acc: 1.0, Train Loss: 3.283406113041565e-05, Lr: 5.504901960784314e-06\n",
      "Train progress bar: 100%|██████████| 136/136 [01:12<00:00,  1.87it/s]\n",
      "Epoch: 21, Train Acc: 0.9995404411764706, Train Loss: 0.0006693839677609503, Lr: 5.333333333333334e-06, Time: 0:01:13\n",
      "Running Validation...\n",
      "Valid progress bar: 100%|██████████| 45/45 [00:06<00:00,  7.42it/s]\n",
      "Valid Acc: 0.9208333333333333, Valid Loss: 0.7339915037155151\n",
      "——————Epoch 23 / 30 ——————\n",
      "Batch: 0, Train Acc: 1.0, Train Loss: 3.7870391679462045e-05, Lr: 5.32843137254902e-06\n",
      "Batch: 50, Train Acc: 1.0, Train Loss: 3.693161852424964e-05, Lr: 5.0833333333333335e-06\n",
      "Batch: 100, Train Acc: 1.0, Train Loss: 3.091188409598544e-05, Lr: 4.838235294117648e-06\n",
      "Train progress bar: 100%|██████████| 136/136 [01:12<00:00,  1.89it/s]\n",
      "Epoch: 22, Train Acc: 1.0, Train Loss: 0.00026193290250375867, Lr: 4.666666666666667e-06, Time: 0:01:12\n",
      "Running Validation...\n",
      "Valid progress bar: 100%|██████████| 45/45 [00:05<00:00,  7.55it/s]\n",
      "Valid Acc: 0.9152777777777777, Valid Loss: 0.7527345418930054\n",
      "——————Epoch 24 / 30 ——————\n",
      "Batch: 0, Train Acc: 1.0, Train Loss: 2.6069166779052466e-05, Lr: 4.6617647058823535e-06\n",
      "Batch: 50, Train Acc: 1.0, Train Loss: 2.8304259103606455e-05, Lr: 4.416666666666667e-06\n",
      "Batch: 100, Train Acc: 1.0, Train Loss: 2.4944161850726232e-05, Lr: 4.1715686274509805e-06\n",
      "Train progress bar: 100%|██████████| 136/136 [01:15<00:00,  1.80it/s]\n",
      "Epoch: 23, Train Acc: 1.0, Train Loss: 3.08790295093786e-05, Lr: 4.000000000000001e-06, Time: 0:01:16\n",
      "Running Validation...\n",
      "Valid progress bar: 100%|██████████| 45/45 [00:06<00:00,  6.67it/s]\n",
      "Valid Acc: 0.9166666666666666, Valid Loss: 0.7722258567810059\n",
      "——————Epoch 25 / 30 ——————\n",
      "Batch: 0, Train Acc: 1.0, Train Loss: 3.114270293735899e-05, Lr: 3.995098039215687e-06\n",
      "Batch: 50, Train Acc: 1.0, Train Loss: 3.5940738598583266e-05, Lr: 3.7500000000000005e-06\n",
      "Batch: 100, Train Acc: 1.0, Train Loss: 3.41005579684861e-05, Lr: 3.504901960784314e-06\n",
      "Train progress bar: 100%|██████████| 136/136 [01:15<00:00,  1.80it/s]\n",
      "Epoch: 24, Train Acc: 1.0, Train Loss: 2.9818647817592137e-05, Lr: 3.3333333333333333e-06, Time: 0:01:15\n",
      "Running Validation...\n",
      "Valid progress bar: 100%|██████████| 45/45 [00:05<00:00,  7.66it/s]\n",
      "Valid Acc: 0.9194444444444444, Valid Loss: 0.7732782363891602\n",
      "——————Epoch 26 / 30 ——————\n",
      "Batch: 0, Train Acc: 1.0, Train Loss: 3.0248613256844692e-05, Lr: 3.3284313725490197e-06\n",
      "Batch: 50, Train Acc: 1.0, Train Loss: 2.8915184884681366e-05, Lr: 3.0833333333333336e-06\n",
      "Batch: 100, Train Acc: 1.0, Train Loss: 2.1435058442875743e-05, Lr: 2.838235294117647e-06\n",
      "Train progress bar: 100%|██████████| 136/136 [01:12<00:00,  1.88it/s]\n",
      "Epoch: 25, Train Acc: 1.0, Train Loss: 2.9030950827291235e-05, Lr: 2.666666666666667e-06, Time: 0:01:13\n",
      "Running Validation...\n",
      "Valid progress bar: 100%|██████████| 45/45 [00:06<00:00,  7.24it/s]\n",
      "Valid Acc: 0.9180555555555555, Valid Loss: 0.7788916230201721\n",
      "——————Epoch 27 / 30 ——————\n",
      "Batch: 0, Train Acc: 1.0, Train Loss: 2.1382889826782048e-05, Lr: 2.6617647058823532e-06\n",
      "Batch: 50, Train Acc: 1.0, Train Loss: 2.6024468752439134e-05, Lr: 2.4166666666666667e-06\n",
      "Batch: 100, Train Acc: 1.0, Train Loss: 2.505584961909335e-05, Lr: 2.1715686274509806e-06\n",
      "Train progress bar: 100%|██████████| 136/136 [01:13<00:00,  1.86it/s]\n",
      "Epoch: 26, Train Acc: 1.0, Train Loss: 2.8184107577544637e-05, Lr: 2.0000000000000003e-06, Time: 0:01:13\n",
      "Running Validation...\n",
      "Valid progress bar: 100%|██████████| 45/45 [00:06<00:00,  7.44it/s]\n",
      "Valid Acc: 0.9166666666666666, Valid Loss: 0.7813230752944946\n",
      "——————Epoch 28 / 30 ——————\n",
      "Batch: 0, Train Acc: 1.0, Train Loss: 2.5368797651026398e-05, Lr: 1.9950980392156867e-06\n",
      "Batch: 50, Train Acc: 1.0, Train Loss: 3.1001320166978985e-05, Lr: 1.75e-06\n",
      "Batch: 100, Train Acc: 1.0, Train Loss: 2.8475500585045666e-05, Lr: 1.5049019607843139e-06\n",
      "Train progress bar: 100%|██████████| 136/136 [01:19<00:00,  1.71it/s]\n",
      "Epoch: 27, Train Acc: 1.0, Train Loss: 2.672280970728025e-05, Lr: 1.3333333333333334e-06, Time: 0:01:20\n",
      "Running Validation...\n",
      "Valid progress bar: 100%|██████████| 45/45 [00:06<00:00,  7.29it/s]\n",
      "Valid Acc: 0.9180555555555555, Valid Loss: 0.7831462621688843\n",
      "——————Epoch 29 / 30 ——————\n",
      "Batch: 0, Train Acc: 1.0, Train Loss: 2.6493691620999016e-05, Lr: 1.3284313725490198e-06\n",
      "Batch: 50, Train Acc: 1.0, Train Loss: 2.8803407985833474e-05, Lr: 1.0833333333333335e-06\n",
      "Batch: 100, Train Acc: 1.0, Train Loss: 1.9982206140412018e-05, Lr: 8.38235294117647e-07\n",
      "Train progress bar: 100%|██████████| 136/136 [01:10<00:00,  1.92it/s]\n",
      "Epoch: 28, Train Acc: 1.0, Train Loss: 0.00012601185881067067, Lr: 6.666666666666667e-07, Time: 0:01:11\n",
      "Running Validation...\n",
      "Valid progress bar: 100%|██████████| 45/45 [00:06<00:00,  7.42it/s]\n",
      "Valid Acc: 0.9111111111111111, Valid Loss: 0.8103207945823669\n",
      "——————Epoch 30 / 30 ——————\n",
      "Batch: 0, Train Acc: 1.0, Train Loss: 2.728348772507161e-05, Lr: 6.61764705882353e-07\n",
      "Batch: 50, Train Acc: 1.0, Train Loss: 3.20216131513007e-05, Lr: 4.1666666666666667e-07\n",
      "Batch: 100, Train Acc: 1.0, Train Loss: 3.121733607258648e-05, Lr: 1.7156862745098042e-07\n",
      "Train progress bar: 100%|██████████| 136/136 [01:11<00:00,  1.91it/s]\n",
      "Epoch: 29, Train Acc: 0.9995404411764706, Train Loss: 0.0033542169257998466, Lr: 0.0, Time: 0:01:11\n",
      "Running Validation...\n",
      "Valid progress bar: 100%|██████████| 45/45 [00:05<00:00,  7.68it/s]\n",
      "Valid Acc: 0.9069444444444444, Valid Loss: 0.8042675852775574\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './fine-tuning-add-epoch-gpu-valid-30epoch.model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35224/2717409463.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./fine-tuning-add-epoch-gpu-valid-30epoch.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mlabels_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './fine-tuning-add-epoch-gpu-valid-30epoch.model'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_dataloader = torch.utils.data.DataLoader(dataset=Dataset('train'), batch_size=16, collate_fn=collate_fn, shuffle=True, drop_last=True)  \n",
    "    valid_dataloader = torch.utils.data.DataLoader(dataset=Dataset('valid'), batch_size=16, collate_fn=collate_fn, shuffle=True, drop_last=True)\n",
    "    test_dataloader = torch.utils.data.DataLoader(dataset=Dataset('test'), batch_size=16, collate_fn=collate_fn, shuffle=True, drop_last=True)\n",
    "    \n",
    "    model = Model()\n",
    "    train(model,train_dataloader,valid_dataloader, num_epoch = 30) # set num_epoch\n",
    "    \n",
    "    model = torch.load('./fine-tuning-add-epoch-gpu-valid-30epoch.model') # modify path to './fine-tuned-bert.model'\n",
    "    labels_list, outs_list = test(model,test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4e7c29ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test...\n",
      "device= cuda\n",
      "Test progress bar: 100%|██████████| 45/45 [00:06<00:00,  7.16it/s]\n",
      "Test Acc: 0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "test(model,test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a91b64b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test...\n",
      "device= cuda\n",
      "Test progress bar: 100%|██████████| 45/45 [00:06<00:00,  7.32it/s]\n",
      "Test Acc: 0.9152777777777777\n",
      "accuracy:0.9152777777777777\n",
      "precision:0.8260869565217391\n",
      "recall:0.8397790055248618\n",
      "f1_score:0.8328767123287671\n",
      "roc_auc:0.8902049016492584\n"
     ]
    }
   ],
   "source": [
    "# 4 epoch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "model = torch.load('./fine-tuning-add-epoch-gpu-valid.model') \n",
    "labels_list, outs_list = test(model,test_dataloader)\n",
    "labels_list_flatten = np.array(labels_list).flatten()\n",
    "outs_list_flatten = np.array(outs_list).flatten()\n",
    "print('accuracy:{}'.format(accuracy_score(labels_list_flatten, outs_list_flatten)))\n",
    "print('precision:{}'.format(precision_score(labels_list_flatten, outs_list_flatten)))\n",
    "print('recall:{}'.format(recall_score(labels_list_flatten, outs_list_flatten)))\n",
    "print('f1_score:{}'.format(f1_score(labels_list_flatten, outs_list_flatten)))\n",
    "fpr,tpr,threshold = roc_curve(labels_list_flatten, outs_list_flatten)\n",
    "roc_auc = auc(fpr,tpr)\n",
    "print('roc_auc:{}'.format(roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1a34d13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test...\n",
      "device= cuda\n",
      "Test progress bar: 100%|██████████| 45/45 [00:06<00:00,  7.12it/s]\n",
      "Test Acc: 0.9194444444444444\n",
      "accuracy:0.9194444444444444\n",
      "precision:0.8324324324324325\n",
      "recall:0.850828729281768\n",
      "f1_score:0.8415300546448088\n",
      "roc_auc:0.8966574073124981\n"
     ]
    }
   ],
   "source": [
    "# 10 epoch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "model = torch.load('./fine-tuning-add-epoch-gpu-valid-10epoch.model') \n",
    "labels_list, outs_list = test(model,test_dataloader)\n",
    "labels_list_flatten = np.array(labels_list).flatten()\n",
    "outs_list_flatten = np.array(outs_list).flatten()\n",
    "print('accuracy:{}'.format(accuracy_score(labels_list_flatten, outs_list_flatten)))\n",
    "print('precision:{}'.format(precision_score(labels_list_flatten, outs_list_flatten)))\n",
    "print('recall:{}'.format(recall_score(labels_list_flatten, outs_list_flatten)))\n",
    "print('f1_score:{}'.format(f1_score(labels_list_flatten, outs_list_flatten)))\n",
    "fpr,tpr,threshold = roc_curve(labels_list_flatten, outs_list_flatten)\n",
    "roc_auc = auc(fpr,tpr)\n",
    "print('roc_auc:{}'.format(roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "121b38ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test...\n",
      "device= cuda\n",
      "Test progress bar: 100%|██████████| 45/45 [00:06<00:00,  7.35it/s]\n",
      "Test Acc: 0.9166666666666666\n",
      "accuracy:0.9166666666666666\n",
      "precision:0.8296703296703297\n",
      "recall:0.8388888888888889\n",
      "f1_score:0.8342541436464089\n",
      "roc_auc:0.8907407407407408\n"
     ]
    }
   ],
   "source": [
    "# 30 epoch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "model = torch.load('./fine-tuning-add-epoch-gpu-valid-30epoch.model') \n",
    "labels_list, outs_list = test(model,test_dataloader)\n",
    "labels_list_flatten = np.array(labels_list).flatten()\n",
    "outs_list_flatten = np.array(outs_list).flatten()\n",
    "print('accuracy:{}'.format(accuracy_score(labels_list_flatten, outs_list_flatten)))\n",
    "print('precision:{}'.format(precision_score(labels_list_flatten, outs_list_flatten)))\n",
    "print('recall:{}'.format(recall_score(labels_list_flatten, outs_list_flatten)))\n",
    "print('f1_score:{}'.format(f1_score(labels_list_flatten, outs_list_flatten)))\n",
    "fpr,tpr,threshold = roc_curve(labels_list_flatten, outs_list_flatten)\n",
    "roc_auc = auc(fpr,tpr)\n",
    "print('roc_auc:{}'.format(roc_auc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (PySpark)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
